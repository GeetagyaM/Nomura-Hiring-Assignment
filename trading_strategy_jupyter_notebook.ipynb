{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q baostock -i https://pypi.tuna.tsinghua.edu.cn/simple/ --trusted-host pypi.tuna.tsinghua.edu.cn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import baostock as bs\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index composition of CSI500 index at date = '2021-01-01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# login system\n",
    "lg = bs.login()\n",
    "# Display login return information\n",
    "print('login respond error_code:'+lg.error_code)\n",
    "print('login respond error_msg:'+lg.error_msg)\n",
    "\n",
    "# Get CSI 500 constituent stocks\n",
    "rs = bs.query_zz500_stocks(date = '2021-01-01')\n",
    "print('query_zz500 error_code:'+rs.error_code)\n",
    "print('query_zz500 error_msg:'+rs.error_msg)\n",
    "\n",
    "#Print the result set\n",
    "zz500_stocks = []\n",
    "\n",
    "with tqdm(total=500, unit=\"record\") as pbar:\n",
    "    while rs.error_code == '0' and rs.next():\n",
    "        # Get a record and merge the records together\n",
    "        zz500_stocks.append(rs.get_row_data())\n",
    "        pbar.update(1)\n",
    "\n",
    "stock_composition = pd.DataFrame(zz500_stocks, columns=rs.fields)\n",
    "# Output the result set to a csv file\n",
    "stock_composition.to_csv(\"./CSI Index Data/zz500_stocks_2021-01-01.csv\", encoding=\"utf-8\", index=False)\n",
    "\n",
    "# Log out of the system\n",
    "bs.logout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>updateDate</th>\n",
       "      <th>code</th>\n",
       "      <th>code_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>500</td>\n",
       "      <td>500</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>1</td>\n",
       "      <td>500</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>2020-12-28</td>\n",
       "      <td>sz.000563</td>\n",
       "      <td>睿创微纳</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        updateDate       code code_name\n",
       "count          500        500       500\n",
       "unique           1        500       500\n",
       "top     2020-12-28  sz.000563      睿创微纳\n",
       "freq           500          1         1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = './CSI Index Data/zz500_stocks_2021-01-01.csv'\n",
    "stock_composition = pd.read_csv(file_path)\n",
    "stock_composition.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 30min bar data from 2022-04-01 to 2022-07-31 for all 500 stocks of the CSI500 index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = '2022-03-15'  #Taking a start date 15 days earlier to be able to calculate features to start trading on 2022-04-01  \n",
    "end_date = '2022-07-31' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find number of trading days during the given duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "login success!\n",
      "login respond error_code:0\n",
      "login respond error_msg:success\n",
      "query_trade_dates respond error_code:0\n",
      "query_trade_dates respond error_msg:success\n",
      "logout success!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<baostock.data.resultset.ResultData at 0x29efe2dd9d0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### login system####\n",
    "lg = bs.login()\n",
    "# Display login return information\n",
    "print('login respond error_code:'+lg.error_code)\n",
    "print('login respond error_msg:'+lg.error_msg)\n",
    "\n",
    "#### Get trading day information####\n",
    "rs = bs.query_trade_dates(start_date=start_date, end_date=end_date)\n",
    "print('query_trade_dates respond error_code:'+rs.error_code)\n",
    "print('query_trade_dates respond error_msg:'+rs.error_msg)\n",
    "\n",
    "#### Print result set####\n",
    "data_list = []\n",
    "while (rs.error_code == '0') & rs.next():\n",
    "    # Get a record and merge the records together\n",
    "    data_list.append(rs.get_row_data())\n",
    "trading_days = pd.DataFrame(data_list, columns=rs.fields)\n",
    "\n",
    "trading_days.to_csv(\"./CSI Index Data/trading_days.csv\", index=False)\n",
    "\n",
    "#### Log out of the system####\n",
    "bs.logout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trading Days: 93\n"
     ]
    }
   ],
   "source": [
    "file_path = \"./CSI Index Data/trading_days.csv\"\n",
    "trading_days = pd.read_csv(file_path)\n",
    "print(\"Trading Days:\",trading_days['is_trading_day'].astype(int).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Stock Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stock_data(stock_code, start_date, end_date):\n",
    "    \n",
    "    # Setting adjustflag to be 2 to adjust for dividends, bonuses, and rights issues\n",
    "    rs = bs.query_history_k_data_plus(stock_code,\n",
    "        \"date,time,code,open,high,low,close,volume,amount,adjustflag\",\n",
    "        start_date=start_date, end_date=end_date,\n",
    "        frequency=\"30\", adjustflag=\"2\")\n",
    "    # print('query_history_k_data_plus respond error_code:'+rs.error_code)\n",
    "    # print('query_history_k_data_plus respond error_msg:'+rs.error_msg)\n",
    "\n",
    "    data_list = []\n",
    "    while (rs.error_code == '0') & rs.next():\n",
    "        # Get a record and merge the records together\n",
    "        data_list.append(rs.get_row_data())\n",
    "    \n",
    "    result = pd.DataFrame(data_list, columns=rs.fields)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "login success!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [06:31<00:00,  1.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logout success!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<baostock.data.resultset.ResultData at 0x2e4f72bc550>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### login system####\n",
    "lg = bs.login()\n",
    "# Display login return information\n",
    "\n",
    "stock_data_consolidated = pd.DataFrame()\n",
    "\n",
    "for stock_code in tqdm(stock_composition['code']):\n",
    "    # print(stock_code)\n",
    "    stock_data = get_stock_data(stock_code, start_date, end_date)\n",
    "    stock_data_consolidated = stock_data_consolidated.append(stock_data)\n",
    "\n",
    "#### Output the result set to a csv file####   \n",
    "stock_data_consolidated.to_csv(\"./CSI Index Data/stock_data.csv\", index=False)\n",
    "\n",
    "#### Log out of the system####\n",
    "bs.logout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>code</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>amount</th>\n",
       "      <th>adjustflag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>370979</th>\n",
       "      <td>2022-07-29</td>\n",
       "      <td>20220729113000000</td>\n",
       "      <td>sz.300699</td>\n",
       "      <td>43.361023</td>\n",
       "      <td>43.576780</td>\n",
       "      <td>43.151430</td>\n",
       "      <td>43.194581</td>\n",
       "      <td>553807</td>\n",
       "      <td>38977724.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370980</th>\n",
       "      <td>2022-07-29</td>\n",
       "      <td>20220729133000000</td>\n",
       "      <td>sz.300699</td>\n",
       "      <td>43.169923</td>\n",
       "      <td>43.169923</td>\n",
       "      <td>42.719916</td>\n",
       "      <td>42.904850</td>\n",
       "      <td>432687</td>\n",
       "      <td>30084125.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370981</th>\n",
       "      <td>2022-07-29</td>\n",
       "      <td>20220729140000000</td>\n",
       "      <td>sz.300699</td>\n",
       "      <td>42.966495</td>\n",
       "      <td>43.126772</td>\n",
       "      <td>42.904850</td>\n",
       "      <td>42.997318</td>\n",
       "      <td>243000</td>\n",
       "      <td>16955343.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370982</th>\n",
       "      <td>2022-07-29</td>\n",
       "      <td>20220729143000000</td>\n",
       "      <td>sz.300699</td>\n",
       "      <td>42.984989</td>\n",
       "      <td>43.693905</td>\n",
       "      <td>42.941837</td>\n",
       "      <td>43.693905</td>\n",
       "      <td>751600</td>\n",
       "      <td>52897905.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370983</th>\n",
       "      <td>2022-07-29</td>\n",
       "      <td>20220729150000000</td>\n",
       "      <td>sz.300699</td>\n",
       "      <td>43.687741</td>\n",
       "      <td>43.693905</td>\n",
       "      <td>43.114443</td>\n",
       "      <td>43.182252</td>\n",
       "      <td>823460</td>\n",
       "      <td>57858656.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              date               time       code       open       high  \\\n",
       "370979  2022-07-29  20220729113000000  sz.300699  43.361023  43.576780   \n",
       "370980  2022-07-29  20220729133000000  sz.300699  43.169923  43.169923   \n",
       "370981  2022-07-29  20220729140000000  sz.300699  42.966495  43.126772   \n",
       "370982  2022-07-29  20220729143000000  sz.300699  42.984989  43.693905   \n",
       "370983  2022-07-29  20220729150000000  sz.300699  43.687741  43.693905   \n",
       "\n",
       "              low      close  volume      amount  adjustflag  \n",
       "370979  43.151430  43.194581  553807  38977724.0           2  \n",
       "370980  42.719916  42.904850  432687  30084125.0           2  \n",
       "370981  42.904850  42.997318  243000  16955343.0           2  \n",
       "370982  42.941837  43.693905  751600  52897905.0           2  \n",
       "370983  43.114443  43.182252  823460  57858656.0           2  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "file_path = \"./CSI Index Data/stock_data.csv\"\n",
    "stock_data_consolidated = pd.read_csv(file_path)\n",
    "display(stock_data_consolidated.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'2022-04-25', '2022-06-21', '2022-04-18', '2022-04-06', '2022-05-27', '2022-06-14', '2022-07-01', '2022-06-29', '2022-06-30', '2022-04-21', '2022-07-04', '2022-07-19', '2022-06-27', '2022-07-25', '2022-07-28', '2022-04-19', '2022-07-08', '2022-05-10', '2022-07-06', '2022-07-26', '2022-06-16', '2022-04-28', '2022-04-01', '2022-06-08', '2022-07-20', '2022-07-22', '2022-04-20', '2022-06-10', '2022-05-31', '2022-03-29', '2022-05-30', '2022-05-16', '2022-06-28', '2022-05-12', '2022-05-11', '2022-05-05', '2022-06-24', '2022-04-27', '2022-07-14', '2022-07-11', '2022-07-15', '2022-06-20', '2022-06-09', '2022-06-01', '2022-07-18', '2022-06-17', '2022-06-02', '2022-06-07', '2022-06-22', '2022-05-09', '2022-07-29', '2022-07-07', '2022-03-30', '2022-06-13', '2022-07-13', '2022-04-29', '2022-06-06', '2022-07-05', '2022-06-23', '2022-05-13', '2022-06-15', '2022-04-26', '2022-07-27', '2022-07-12', '2022-03-31', '2022-05-18', '2022-07-21', '2022-04-22', '2022-05-26', '2022-05-06', '2022-05-25'}\n"
     ]
    }
   ],
   "source": [
    "code_counts = stock_data_consolidated['code'].value_counts()\n",
    "all_days = set(stock_data_consolidated['date'].unique())\n",
    "\n",
    "# Filter the codes that have less than 744 entries\n",
    "codes_with_less_than_744_entries = code_counts[code_counts < 744]\n",
    "# print(codes_with_less_than_744_entries)\n",
    "days_with_missing_data = set()\n",
    "days_with_missing_data_dict = {}\n",
    "\n",
    "for stock_code in codes_with_less_than_744_entries.index:\n",
    "    stock_data = stock_data_consolidated[stock_data_consolidated['code'] == stock_code]\n",
    "    missing_days = all_days - set(stock_data['date'])\n",
    "    # print(missing_days)\n",
    "    days_with_missing_data_dict[stock_code] = list(missing_days)\n",
    "    days_with_missing_data = days_with_missing_data.union(missing_days)\n",
    "print(days_with_missing_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove Stocks that have missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(361584, 10)\n"
     ]
    }
   ],
   "source": [
    "# Ommiting the 14 stocks for which 30 min bar data is not available, that leaves us with 486 stocks\n",
    "stock_data_consolidated = stock_data_consolidated[~stock_data_consolidated['code'].isin(days_with_missing_data_dict.keys())].reset_index(drop=True)\n",
    "stock_data_consolidated.describe(include='all')\n",
    "\n",
    "stock_data_consolidated['date'].unique()\n",
    "print(stock_data_consolidated.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_stocks': 486, 'per_stock_amount': 205761.316872428, 'money_left': 4760.6345786601305, 'money_invested': 99995239.36542134, 'money_retrieved': 103202192.18878993, 'closing_amount': 103206952.8233686, 'profit_pct_based_initial_amount': 3.206952823368603}\n",
      "{'n_stocks': 486, 'per_stock_amount': 205761.316872428, 'money_left': 4725.580471023917, 'money_invested': 99995274.41952898, 'money_retrieved': 98590602.15682344, 'closing_amount': 98595327.73729447, 'profit_pct_based_initial_amount': -1.4046722627055308}\n"
     ]
    }
   ],
   "source": [
    "# Assuming the availaible amount to be CNY 100M\n",
    "AMOUNT = 100000000 \n",
    "\n",
    "def calculate_investment_profit(stock_data=stock_data_consolidated, initial_amount=AMOUNT, start_time=20220401100000000, end_time=20220630150000000):\n",
    "    if start_time not in stock_data['time'].values:\n",
    "        raise ValueError(\"Start time not found in the DataFrame.\")\n",
    "    if end_time not in stock_data['time'].values:\n",
    "        raise ValueError(\"End time not found in the DataFrame.\")\n",
    "\n",
    "    n_stocks = stock_data['code'].unique().shape[0]\n",
    "    per_stock_amount = initial_amount / n_stocks\n",
    "\n",
    "    stock_prices_start = stock_data.loc[stock_data['time'] == start_time, ['code', 'close']].reset_index(drop=True)\n",
    "    quantities_bought = per_stock_amount // stock_prices_start['close']\n",
    "    money_invested_per_stock = stock_prices_start['close'] * quantities_bought\n",
    "    money_invested = money_invested_per_stock.sum()\n",
    "    money_left = initial_amount - money_invested\n",
    "\n",
    "    stock_prices_end = stock_data.loc[stock_data['time'] == end_time, ['code', 'close']].reset_index(drop=True)\n",
    "    quantities_sold = quantities_bought\n",
    "    money_retrieved = (stock_prices_end['close'] * quantities_sold).sum()\n",
    "    closing_amount = money_retrieved + money_left\n",
    "    profit_pct_based_initial_amount = (closing_amount / initial_amount - 1) * 100\n",
    "\n",
    "    result = {\n",
    "        \"n_stocks\": n_stocks,\n",
    "        \"per_stock_amount\": per_stock_amount,\n",
    "        \"money_left\": money_left,\n",
    "        \"money_invested\": money_invested,\n",
    "        \"money_retrieved\": money_retrieved,\n",
    "        \"closing_amount\": closing_amount,\n",
    "        \"profit_pct_based_initial_amount\": profit_pct_based_initial_amount,\n",
    "    }\n",
    "\n",
    "    return result\n",
    "\n",
    "# Usage example:\n",
    "# result = calculate_investment_profit(stock_data_consolidated, start_time=20220401100000000, end_time=20220630150000000)\n",
    "# print(result)\n",
    "\n",
    "\n",
    "result = calculate_investment_profit()\n",
    "print(result)\n",
    "\n",
    "result_out_sample = calculate_investment_profit(start_time=20220701100000000, end_time=20220729150000000)\n",
    "print(result_out_sample)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features\n",
    "# 1. SMA \n",
    "# 2. EMA\n",
    "# 3. Z-Score\n",
    "# 4. RSI\n",
    "\n",
    "def calculate_sma(series , window):\n",
    "    return series.rolling(window=window).mean()\n",
    "\n",
    "def calculate_ema(series, span):\n",
    "    return series.ewm(span=span, adjust=False).mean()\n",
    "\n",
    "def calculate_zscore(series, window):\n",
    "    rolling_mean = series.rolling(window=window).mean()\n",
    "    rolling_std = series.rolling(window=window).std()\n",
    "    z_score = (series - rolling_mean) / rolling_std\n",
    "    return z_score\n",
    "\n",
    "def calculate_rsi(series, window):\n",
    "    delta = series.diff()\n",
    "    gain = delta.where(delta > 0, 0)\n",
    "    loss = -delta.where(delta < 0, 0)\n",
    "    \n",
    "    avg_gain = gain.rolling(window=window, min_periods=1).mean()\n",
    "    avg_loss = loss.rolling(window=window, min_periods=1).mean()\n",
    "    \n",
    "    rs = avg_gain / avg_loss\n",
    "    rsi = 100 - (100 / (1 + rs))\n",
    "    \n",
    "    return rsi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_indicators(df, long_window, long_to_short_ratio, z_score_centre, long_ma_type, short_ma_type):\n",
    "    \n",
    "    short_window = long_window // long_to_short_ratio\n",
    "    grouped = df.groupby('code')\n",
    "\n",
    "    if long_ma_type == 'sma':\n",
    "        long_ma_func = lambda x: calculate_sma(x, long_window)\n",
    "    elif long_ma_type == 'ema':\n",
    "        long_ma_func = lambda x: calculate_ema(x, long_window)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid 'long_ma_type'. Use 'sma' or 'ema'.\")\n",
    "\n",
    "    if short_ma_type == 'sma':\n",
    "        short_ma_func = lambda x: calculate_sma(x, short_window)\n",
    "    elif short_ma_type == 'ema':\n",
    "        short_ma_func = lambda x: calculate_ema(x, short_window)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid 'short_ma_type'. Use 'sma' or 'ema'.\")\n",
    "\n",
    "    # Calculate selected moving averages, Z-Score, RSI for each group\n",
    "    df['long MA'] = grouped['close'].apply(long_ma_func)\n",
    "    df['short MA'] = grouped['close'].apply(short_ma_func)\n",
    "    df['Z-Score'] = grouped['close'].apply(lambda x: calculate_zscore(x, long_window))\n",
    "    df['RSI'] = grouped['close'].apply(lambda x: calculate_rsi(x, short_window))\n",
    "\n",
    "    return df   \n",
    "\n",
    "def prepare_filters(df, rsi_l, rsi_u, z_score_centre):\n",
    "    df['MA_Down_Cross'] = (df['short MA'] < df['long MA']).astype(int)\n",
    "    df['RSI_b/w_bounds'] = ((df['RSI'] >= rsi_l) & (df['RSI'] <= rsi_u)).astype(int)\n",
    "\n",
    "    df['Z_Score_Trigger'] = 0\n",
    "    z_score = df['Z-Score']\n",
    "\n",
    "    # Apply the logic to set the trigger values\n",
    "    df.loc[(z_score < 0) & (z_score >= -z_score_centre), 'Z_Score_Trigger'] = 1\n",
    "    df.loc[(z_score < -z_score_centre) & (z_score >= -2*z_score_centre), 'Z_Score_Trigger'] = 2\n",
    "\n",
    "    df['weights'] = df['MA_Down_Cross'] * df['RSI_b/w_bounds'] * df['Z_Score_Trigger']\n",
    "    df['weights_normalized'] = df.groupby('time')['weights'].transform(lambda x: x / x.sum())\n",
    "    df['weights_normalized'].fillna(0, inplace=True)    \n",
    "    \n",
    "\n",
    "    return df \n",
    "\n",
    "def trade(df, start_date, end_date, initial_amount):\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df = df[(df['date'] >= start_date) & (df['date'] <= end_date)]\n",
    "\n",
    "    time_stamps = df['time'].unique()\n",
    "\n",
    "    portfolio = pd.DataFrame()\n",
    "    portfolio['stocks'] = df['code'].unique()\n",
    "    portfolio['quantities'] = 0\n",
    "\n",
    "    trade_logs = pd.DataFrame(index = time_stamps)\n",
    "    cash = initial_amount\n",
    "\n",
    "    for ts in time_stamps:\n",
    "        \n",
    "        # Get the rows of the df for current timestamp\n",
    "        current_timestamp = df[df['time']==ts]\n",
    "        current_prices = current_timestamp['close'].reset_index(drop = True)\n",
    "        \n",
    "        # Find effective money availaible\n",
    "        stock = (portfolio['quantities'] * current_prices).sum()\n",
    "        effective_money_available = stock + cash\n",
    "        \n",
    "        # Get the ideal portfolio composition for current timestamp\n",
    "        ideal_weights = current_timestamp['weights_normalized'].reset_index(drop = True)\n",
    "        per_stock_amount = ideal_weights * effective_money_available\n",
    "        ideal_composition = per_stock_amount//current_prices\n",
    "\n",
    "        # Get the changes in composition for current timestamp\n",
    "        changes_in_composition = ideal_composition - portfolio['quantities']\n",
    "\n",
    "        # Update new quantities of the stocks in the portfolio and cash availaible\n",
    "        portfolio['quantities'] = ideal_composition\n",
    "        money_invested = (ideal_composition * current_prices).sum()\n",
    "        cash = effective_money_available - money_invested\n",
    "        \n",
    "        # Update the trade logs\n",
    "        trade_logs.loc[ts,'trxns']      = str(list(changes_in_composition))\n",
    "        trade_logs.loc[ts,'stock']      = money_invested\n",
    "        trade_logs.loc[ts,'cash']       = cash\n",
    "        trade_logs.loc[ts,'eff_mon']    = effective_money_available\n",
    "    \n",
    "    return trade_logs\n",
    "\n",
    "# Calls all three functions above\n",
    "def run_trading_strategy(df, start_date, end_date, long_window, long_to_short_ratio, rsi_bounds, z_score_centre, long_ma_type, short_ma_type, initial_amount):\n",
    "\n",
    "    df_with_indicators = prepare_indicators(df, long_window, long_to_short_ratio, z_score_centre, long_ma_type, short_ma_type)\n",
    "    df_with_filters = prepare_filters(df_with_indicators, rsi_bounds[0], rsi_bounds[1], z_score_centre)\n",
    "    trade_logs = trade(df, start_date, end_date, initial_amount)\n",
    "    return trade_logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Backtest for various hyperparam configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [30:03<00:00,  3.13s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import json\n",
    "# Define the parameter combinations\n",
    "dates_list = [('2022-04-01', '2022-06-30'), ('2022-07-01', '2022-07-29')]\n",
    "long_ma_types = ['sma', 'ema']\n",
    "short_ma_types = ['sma', 'ema']\n",
    "long_windows = [60, 72, 84, 96]\n",
    "long_to_short_ratios = [2, 3, 4]\n",
    "rsi_bounds_list = [(20, 80), (30, 70), (40, 60)]\n",
    "z_score_centres = [1, 0.75]\n",
    "\n",
    "# Initialize the progress bar\n",
    "total_iterations = (\n",
    "    len(dates_list)\n",
    "    * len(long_ma_types)\n",
    "    * len(short_ma_types)\n",
    "    * len(long_windows)\n",
    "    * len(long_to_short_ratios)\n",
    "    * len(rsi_bounds_list)\n",
    "    * len(z_score_centres)\n",
    ")\n",
    "pbar = tqdm(total=total_iterations)\n",
    "results = []\n",
    "index = 0\n",
    "# Iterate through parameter combinations\n",
    "for dates in dates_list:\n",
    "    for long_ma_type in long_ma_types:\n",
    "        for short_ma_type in short_ma_types:\n",
    "            for long_window in long_windows:\n",
    "                for long_to_short_ratio in long_to_short_ratios:\n",
    "                    for rsi_bounds in rsi_bounds_list:\n",
    "                        for z_score_centre in z_score_centres:\n",
    "                            trade_logs = run_trading_strategy(\n",
    "                                df=stock_data_consolidated,\n",
    "                                start_date=dates[0],\n",
    "                                end_date=dates[1],\n",
    "                                long_window=long_window,\n",
    "                                long_to_short_ratio=long_to_short_ratio,\n",
    "                                rsi_bounds=rsi_bounds,\n",
    "                                z_score_centre=z_score_centre,\n",
    "                                long_ma_type=long_ma_type,\n",
    "                                short_ma_type=short_ma_type,\n",
    "                                initial_amount=100000000\n",
    "                            )\n",
    "\n",
    "                            # Save configuration and trade logs\n",
    "                            config = {\n",
    "                                \"dates\": dates,\n",
    "                                \"long_ma_type\": long_ma_type,\n",
    "                                \"short_ma_type\": short_ma_type,\n",
    "                                \"long_window\": long_window,\n",
    "                                \"long_to_short_ratio\": long_to_short_ratio,\n",
    "                                \"rsi_bounds\": rsi_bounds,\n",
    "                                \"z_score_centre\": z_score_centre,\n",
    "                            }\n",
    "                            results.append({\"config\": config, \"trade_logs\": trade_logs})\n",
    "\n",
    "                            with open(f\"./JSONs/config_{index}.json\", 'w') as config_file:\n",
    "                                json.dump(config, config_file)\n",
    "\n",
    "                            # Save the trade logs as a CSV file\n",
    "                            trade_logs.to_csv(f\"./CSVs/trade_logs_{index}.csv\", index=False)\n",
    "\n",
    "                            # Update the progress bar\n",
    "                            pbar.update(1)\n",
    "                            index+=1\n",
    "\n",
    "# Close the progress bar\n",
    "pbar.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate performance metrics for each hyperparam config backtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def calculate_metrics(value_series):\n",
    "    \n",
    "    total_return_percent = (value_series.iloc[-1]/value_series.iloc[0]-1) * 100\n",
    "\n",
    "    cummax = value_series.cummax()\n",
    "    drawdown = (value_series - cummax) / cummax * 100\n",
    "    max_drawdown = drawdown.min()\n",
    "\n",
    "    return_series = value_series.pct_change()\n",
    "    volatility = return_series.std() * np.sqrt(return_series.size) * 100\n",
    "\n",
    "    result_dict = {\n",
    "    'total_return_percent': total_return_percent,\n",
    "    'volatility': volatility,\n",
    "    'max_drawdown': max_drawdown,\n",
    "    'return_per_unit_risk':total_return_percent/volatility\n",
    "    }\n",
    "\n",
    "    return result_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/576 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:09<00:00, 63.42it/s] \n"
     ]
    }
   ],
   "source": [
    "final_output = []\n",
    "\n",
    "for index in tqdm(range(total_iterations)):\n",
    "    # Load the config from JSON\n",
    "    with open(f\"./JSONs/config_{index}.json\", 'r') as config_file:\n",
    "        config = json.load(config_file)\n",
    "\n",
    "    # Read the trade logs from CSV\n",
    "    trade_logs = pd.read_csv(f\"./CSVs/trade_logs_{index}.csv\")\n",
    "    performance_metrics = calculate_metrics(trade_logs['eff_mon'])\n",
    "    combined_data = {**config, **performance_metrics}\n",
    "    final_output.append(combined_data)\n",
    "\n",
    "result_df = pd.DataFrame(final_output)\n",
    "result_df.to_csv(f\"result_df.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
